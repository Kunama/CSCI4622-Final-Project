{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income Classification - Akhil Kunam, Sebastian Poellinger, Yuri Han\n",
    "### Project Topic\n",
    "Our project's goal is to classify individual income as above 50k per year or less than 50k per year based on various attirbutes. There are 14 features such as age, workclass, education, and race. We will use these features to classify each individual into their income group. We chose this topic as it is a way to allow us to determine if certain factors cause people to earn more than others and possibly explain some income inequality. Another reason was that this data is easily classifiable so it can help us master some classifcation models.\n",
    "\n",
    "\n",
    "### Data\n",
    "Data Source Link: http://archive.ics.uci.edu/ml/datasets/Adult\n",
    "We got our data from UCI. UCI has a \"Center for Machine Learning and Intelligent Systems\" which provides the public around 500 data sets. It is based off of census data  from 1994 and has 48,842 samples split into 32,561 data points for training and 16281 data points for testing. Each data point has its relevant 14 features as well as its classification as \"<=50k\" or \">50k\". The 14 features break down as 6 numeric and 8 categorical. Below is a breakdown for each feature \n",
    "\n",
    "Age: Numerical value representing age of the individual \n",
    "\n",
    "Workclass: Categorical value representing if the individual is self employed, working for government, private, etc. There are 8 values for this field. \n",
    "\n",
    "Fnlwgt: This is a numerical value that tells us how many people this sample represents as believed by the census. \n",
    "\n",
    "Education: Categorical value representing the highest level of education for the individual. There are 16 values for this.  \n",
    "\n",
    "Education-num: Numerical value that represents the highest level of education as the corresponding grade number. \n",
    "\n",
    "Marital-status: Categorical variable with 7 values representing the status of the individuals marriage. \n",
    "\n",
    "Occupation: Categorical variable with 14 values representing the type of work the individual does. \n",
    "\n",
    "Relationship: Categorical variable with 6 values representing the individuals relationship status. \n",
    "\n",
    "Race: Categorical value with 5 values showing the race of the individual. \n",
    "\n",
    "Sex: Categorical value representing the gender of the person. \n",
    "\n",
    "Capital-gain: Numerical value representing how much the individual gained when selling investments. \n",
    "\n",
    "Capital-loss: Numerical value representing how much the individual lost when selling investments. \n",
    "\n",
    "Hours-per-week: Numerical value representing how many hours the individual works per week. \n",
    "\n",
    "Native-country: Categorical variable with 41 values representing the individuals native country. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our data cleaning we first started off by finding which columns had '?' as a value. When we were doing a rough skim over the csv files we saw that all the unknown values were represented as '?' so we wanted to know in which columns those were found and how we can go about fixing them. We learned that they were in the workclass, occupation, and native-country columns. For the workclass and native country features we saw that the most common feature was found way more than the second most common so we decided to impute the '?' values as the most common value for the feature since it was likely it would be that value. For occupation the counts for each value were around the same so we couldn't impute them and decided to leave those values as is. We did dropna to make sure we didn't have any samples with a NaN value for any of their features. \n",
    "\n",
    "Next we wanted to convert the income classification from a string to a numeric value that would be easily used for our models. We did this through the map function for the dataframe. We also learned that the 'fnlwgt' feature was mainly only important for the people reading the census and had no effect on the income so we decided it would be best to drop that feature. \n",
    "\n",
    "We printed out the values for all the features we had left and saw that the education and education-num features were the exact same since education-num was the numerical representation of the value in the education feature. We decided that we can drop education as we have all that information already in the education-num column. \n",
    "\n",
    "We also did data type munging since we had several categorical features and wanted to convert them to numeric so that our models would be able to use them. We used sklearn's LabelEncoder to do this for us. It would take the values and change them to a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "df = pd.read_csv(\"adult.data\", names=names, skipinitialspace=True)\n",
    "df_test = pd.read_csv(\"adult.test\", names=names, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0\n",
      "workclass: 1836\n",
      "fnlwgt: 0\n",
      "education: 0\n",
      "education-num: 0\n",
      "marital-status: 0\n",
      "occupation: 1843\n",
      "relationship: 0\n",
      "race: 0\n",
      "sex: 0\n",
      "capital-gain: 0\n",
      "capital-loss: 0\n",
      "hours-per-week: 0\n",
      "native-country: 583\n",
      "income: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilkunam/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "#Count all the ? entries for each featuree\n",
    "for column in df.columns:\n",
    "    print(column + \": {}\".format((df[column] == '?').sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private             22696\n",
      "Self-emp-not-inc     2541\n",
      "Local-gov            2093\n",
      "Name: workclass, dtype: int64\n",
      "United-States    29170\n",
      "Mexico             643\n",
      "?                  583\n",
      "Name: native-country, dtype: int64\n",
      "Prof-specialty     4140\n",
      "Craft-repair       4099\n",
      "Exec-managerial    4066\n",
      "Name: occupation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['workclass'].value_counts().head(3))\n",
    "print(df['native-country'].value_counts().head(3))\n",
    "print(df['occupation'].value_counts().head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"workclass\"] = df[\"workclass\"].replace('?', 'Private')\n",
    "df[\"native-country\"] = df[\"native-country\"].replace('?', 'United-States')\n",
    "\n",
    "df_test[\"workclass\"] = df_test[\"workclass\"].replace('?', 'Private')\n",
    "df_test[\"native-country\"] = df_test[\"native-country\"].replace('?', 'United-States')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the income numerical\n",
    "# print((df[\"income\"] == ' <=50K').sum())\n",
    "df[\"income\"] = df[\"income\"].map({\"<=50K\":0, \">50K\":1})\n",
    "df_test[\"income\"] = df_test[\"income\"].map({\"<=50K.\":0, \">50K.\":1})\n",
    "#drop fnlweight as it is only interesting for the census authorities\n",
    "df = df.drop(labels=\"fnlwgt\", axis=1)\n",
    "df_test = df_test.drop(labels=\"fnlwgt\", axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36    898\n",
      "31    888\n",
      "34    886\n",
      "23    877\n",
      "35    876\n",
      "     ... \n",
      "83      6\n",
      "85      3\n",
      "88      3\n",
      "87      1\n",
      "86      1\n",
      "Name: age, Length: 73, dtype: int64\n",
      "Private             24532\n",
      "Self-emp-not-inc     2541\n",
      "Local-gov            2093\n",
      "State-gov            1298\n",
      "Self-emp-inc         1116\n",
      "Federal-gov           960\n",
      "Without-pay            14\n",
      "Never-worked            7\n",
      "Name: workclass, dtype: int64\n",
      "HS-grad         10501\n",
      "Some-college     7291\n",
      "Bachelors        5355\n",
      "Masters          1723\n",
      "Assoc-voc        1382\n",
      "11th             1175\n",
      "Assoc-acdm       1067\n",
      "10th              933\n",
      "7th-8th           646\n",
      "Prof-school       576\n",
      "9th               514\n",
      "12th              433\n",
      "Doctorate         413\n",
      "5th-6th           333\n",
      "1st-4th           168\n",
      "Preschool          51\n",
      "Name: education, dtype: int64\n",
      "9     10501\n",
      "10     7291\n",
      "13     5355\n",
      "14     1723\n",
      "11     1382\n",
      "7      1175\n",
      "12     1067\n",
      "6       933\n",
      "4       646\n",
      "15      576\n",
      "5       514\n",
      "8       433\n",
      "16      413\n",
      "3       333\n",
      "2       168\n",
      "1        51\n",
      "Name: education-num, dtype: int64\n",
      "Married-civ-spouse       14976\n",
      "Never-married            10683\n",
      "Divorced                  4443\n",
      "Separated                 1025\n",
      "Widowed                    993\n",
      "Married-spouse-absent      418\n",
      "Married-AF-spouse           23\n",
      "Name: marital-status, dtype: int64\n",
      "Prof-specialty       4140\n",
      "Craft-repair         4099\n",
      "Exec-managerial      4066\n",
      "Adm-clerical         3770\n",
      "Sales                3650\n",
      "Other-service        3295\n",
      "Machine-op-inspct    2002\n",
      "?                    1843\n",
      "Transport-moving     1597\n",
      "Handlers-cleaners    1370\n",
      "Farming-fishing       994\n",
      "Tech-support          928\n",
      "Protective-serv       649\n",
      "Priv-house-serv       149\n",
      "Armed-Forces            9\n",
      "Name: occupation, dtype: int64\n",
      "Husband           13193\n",
      "Not-in-family      8305\n",
      "Own-child          5068\n",
      "Unmarried          3446\n",
      "Wife               1568\n",
      "Other-relative      981\n",
      "Name: relationship, dtype: int64\n",
      "White                 27816\n",
      "Black                  3124\n",
      "Asian-Pac-Islander     1039\n",
      "Amer-Indian-Eskimo      311\n",
      "Other                   271\n",
      "Name: race, dtype: int64\n",
      "Male      21790\n",
      "Female    10771\n",
      "Name: sex, dtype: int64\n",
      "0        29849\n",
      "15024      347\n",
      "7688       284\n",
      "7298       246\n",
      "99999      159\n",
      "         ...  \n",
      "4931         1\n",
      "1455         1\n",
      "6097         1\n",
      "22040        1\n",
      "1111         1\n",
      "Name: capital-gain, Length: 119, dtype: int64\n",
      "0       31042\n",
      "1902      202\n",
      "1977      168\n",
      "1887      159\n",
      "1848       51\n",
      "        ...  \n",
      "1411        1\n",
      "1539        1\n",
      "2472        1\n",
      "1944        1\n",
      "2201        1\n",
      "Name: capital-loss, Length: 92, dtype: int64\n",
      "40    15217\n",
      "50     2819\n",
      "45     1824\n",
      "60     1475\n",
      "35     1297\n",
      "      ...  \n",
      "92        1\n",
      "94        1\n",
      "87        1\n",
      "74        1\n",
      "82        1\n",
      "Name: hours-per-week, Length: 94, dtype: int64\n",
      "United-States                 29753\n",
      "Mexico                          643\n",
      "Philippines                     198\n",
      "Germany                         137\n",
      "Canada                          121\n",
      "Puerto-Rico                     114\n",
      "El-Salvador                     106\n",
      "India                           100\n",
      "Cuba                             95\n",
      "England                          90\n",
      "Jamaica                          81\n",
      "South                            80\n",
      "China                            75\n",
      "Italy                            73\n",
      "Dominican-Republic               70\n",
      "Vietnam                          67\n",
      "Guatemala                        64\n",
      "Japan                            62\n",
      "Poland                           60\n",
      "Columbia                         59\n",
      "Taiwan                           51\n",
      "Haiti                            44\n",
      "Iran                             43\n",
      "Portugal                         37\n",
      "Nicaragua                        34\n",
      "Peru                             31\n",
      "France                           29\n",
      "Greece                           29\n",
      "Ecuador                          28\n",
      "Ireland                          24\n",
      "Hong                             20\n",
      "Cambodia                         19\n",
      "Trinadad&Tobago                  19\n",
      "Thailand                         18\n",
      "Laos                             18\n",
      "Yugoslavia                       16\n",
      "Outlying-US(Guam-USVI-etc)       14\n",
      "Honduras                         13\n",
      "Hungary                          13\n",
      "Scotland                         12\n",
      "Holand-Netherlands                1\n",
      "Name: native-country, dtype: int64\n",
      "0    24720\n",
      "1     7841\n",
      "Name: income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells education and education-num are equal, which means we can drop the non numerical education column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels=\"education\", axis=1)\n",
    "df_test = df_test.drop(labels=\"education\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualization of each column in frequency\n",
    "# for column in df.columns:\n",
    "#     values = df[column].value_counts().sort_index()\n",
    "#     categories = df[column].unique()\n",
    "#     ax = values.plot.bar(title=column, figsize=(12,6))\n",
    "#     ax.set_ylabel(\"Frequency\", fontsize=16)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop fnlweight as it is only interesting for the census authorities\n",
    "#df = df.drop(labels=\"native-country\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data for the pca and further processing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x = df.drop(labels=\"income\", axis=1)\n",
    "train_y = df[\"income\"]\n",
    "test_x = df_test.drop(labels=\"income\", axis=1)\n",
    "test_y = df_test[\"income\"]\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, test_size=2/10, random_state=0)\n",
    "# print(train_x.shape)\n",
    "# print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education-num  marital-status  occupation  relationship  \\\n",
       "0   39          6             13               4           1             1   \n",
       "1   50          5             13               2           4             0   \n",
       "2   38          3              9               0           6             1   \n",
       "3   53          3              7               2           6             0   \n",
       "4   28          3             13               2          10             5   \n",
       "\n",
       "   race  sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0     4    1          2174             0              40              38  \n",
       "1     4    1             0             0              13              38  \n",
       "2     4    1             0             0              40              38  \n",
       "3     2    1             0             0              40              38  \n",
       "4     2    0             0             0              40               4  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the categorical data to numerical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "features_to_encode = [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "for feature in features_to_encode:\n",
    "    train_x[feature] = le.fit_transform(train_x[feature])\n",
    "    test_x[feature] = le.fit_transform(test_x[feature])\n",
    "\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 8)\n"
     ]
    }
   ],
   "source": [
    "#perform pca to see if we can drop even more columns which might be correlated. \n",
    "#martial status and relationship seem pretty similar to begin with\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#use labelencoder to encode the string labels to int\n",
    "\n",
    "\n",
    "#scales the data to the standard normal, as is required for pca of sklearn\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x)\n",
    "train_x_norm = scaler.transform(train_x)\n",
    "test_x_norm = scaler.transform(test_x)\n",
    "\n",
    "pca = PCA(0.75)\n",
    "pca.fit(train_x_norm)\n",
    "\n",
    "train_x_pca = pca.transform(train_x_norm)\n",
    "test_x_pca = pca.transform(test_x_norm)\n",
    "print(train_x_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8533873840673177"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=0, n_estimators = 100, n_jobs = -1, )\n",
    "\n",
    "model.fit(train_x, train_y)\n",
    "model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1000 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'oob_score': False, 'n_estimators': 50, 'min_weight_fraction_leaf': 0, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0, 'max_samples': 0.5, 'max_leaf_nodes': None, 'max_features': 'auto', 'max_depth': None, 'criterion': 'gini', 'class_weight': None, 'ccp_alpha': 0, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [50] #This should always be best at higher numbers. Using low number so we can test many of the other hyperparams\n",
    "\n",
    "# criterion = ['gini', 'entropy']\n",
    "# max_depth = [None, 10, 25, 50]\n",
    "# min_samples_split = [2, 5, 10, 25]\n",
    "# min_samples_leaf = [1, 2, 5, 10, 25]\n",
    "# min_weight_fraction_leaf = [0, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "# max_features = ['auto', 'sqrt', 'log2', None]\n",
    "# max_leaf_nodes = [None, 1, 2, 5, 10, 25]\n",
    "# min_impurity_decrease = [0, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "# # min_impurity_split = [] Deprecated \n",
    "# bootstrap = [True, False]\n",
    "# oob_score = [True, False]\n",
    "# class_weight = [None, 'balanced', 'balanced_subsample']\n",
    "# ccp_alpha = [0, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "# max_samples = [None, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "# After a few runs we narrowed down the hyper params\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [None, 1, 2, 5, 10, 25]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "min_weight_fraction_leaf = [0, 0.1, 0.05]\n",
    "max_features = ['auto']\n",
    "max_leaf_nodes = [None, 1, 2, 5, 10, 25]\n",
    "min_impurity_decrease = [0, 0.05, 0.1]\n",
    "# min_impurity_split = [] Deprecated \n",
    "bootstrap = [True, False]\n",
    "oob_score = [False]\n",
    "class_weight = [None, 'balanced', 'balanced_subsample']\n",
    "ccp_alpha = [0, 0.1, 0.05]\n",
    "max_samples = [None, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "hyperparams = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'criterion': criterion,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_weight_fraction_leaf': min_weight_fraction_leaf,\n",
    "    'max_features': max_features,\n",
    "    'max_leaf_nodes': max_leaf_nodes,\n",
    "    'min_impurity_decrease': min_impurity_decrease,\n",
    "    'bootstrap': bootstrap,\n",
    "    'oob_score': oob_score,\n",
    "    'class_weight': class_weight,\n",
    "    'ccp_alpha': ccp_alpha,\n",
    "    'max_samples': max_samples\n",
    "}\n",
    "\n",
    "base_model = RandomForestClassifier()\n",
    "optimal_model = RandomizedSearchCV(estimator = base_model, param_distributions = hyperparams, n_iter = 1000, cv = 2, verbose=3, random_state=0, n_jobs = -1)\n",
    "optimal_model.fit(train_x, train_y)\n",
    "print(optimal_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8576868742706222"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(optimal_model.best_estimator_.score(test_x, test_y))\n",
    "test = RandomForestClassifier(**optimal_model.best_params_)\n",
    "test.set_params(n_estimators=500)\n",
    "test.fit(train_x, train_y)\n",
    "# test.get_params()\n",
    "test.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8643817947300534"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_model = RandomForestClassifier(n_estimators = 250, min_samples_split = 2, min_samples_leaf = 4, max_features = 'auto', max_depth = 20, bootstrap = False, n_jobs=-1)\n",
    "# opt_model.get_params()\n",
    "opt_model.fit(train_x, train_y)\n",
    "opt_model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728579325594251"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), n_estimators=80, random_state=0)\n",
    "ada.fit(train_x, train_y)\n",
    "ada.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8718137706529083"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada2 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2, max_leaf_nodes=10), n_estimators=300, random_state=0, learning_rate=1)\n",
    "ada2.fit(train_x, train_y)\n",
    "ada2.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8700325532829679"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada3 = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators = 250, min_samples_split = 2, min_samples_leaf = 4, max_features = 'auto', max_depth = 20, bootstrap = False, n_jobs=-1), n_estimators=4, random_state=0, learning_rate=1)\n",
    "ada3.fit(train_x, train_y)\n",
    "ada3.score(test_x, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8024077145138505"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(train_x, train_y)\n",
    "svm.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8735335667342301"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier(loss=\"exponential\", learning_rate=.2, subsample=1, n_estimators=200)\n",
    "GBC.fit(train_x, train_y)\n",
    "GBC.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654873779251888"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag = BaggingClassifier(n_estimators=100, n_jobs=-1, max_samples=0.20, max_features=0.65, oob_score=True)\n",
    "bag.fit(train_x, train_y)\n",
    "bag.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
